{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWhdm8qGjDGh"
   },
   "outputs": [],
   "source": [
    "## COMP9517 Computer Vision Project 20T2\n",
    "# code: Main program for the project\n",
    "#\n",
    "# Group C:\n",
    "# Connor Baginski (z5207788)\n",
    "# Bhumika Singhal (z5234799)\n",
    "# Rishav Guha (z5294757)\n",
    "# Amel Johny (z5294308)\n",
    "\n",
    "\n",
    "# from cell_tracking.kalmanFilter import KalmanFilter\n",
    "# from scipy.optimize import linear_sum_assignment\n",
    "# # from cell_tracking.tracking_objects  import Tracker \n",
    "# from cell_tracking.tracking_objects  import Track \n",
    "from cell_tracking.helpers import fi_list, find_labels, find_centers, plot_rectangles,draw_path\n",
    "from cell_tracking.pathTracking import PathTracker\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from skimage.morphology import watershed, disk\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.filters import meijering\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "\n",
    "def fi_list(path):\n",
    "    \"\"\"\n",
    "    Return a sorted list of filenames in a given path\n",
    "    \"\"\"\n",
    "    return sorted([os.path.join(path, f) for f in os.listdir(path)])\n",
    "\n",
    "def custom_thresh(image):\n",
    "    for r in range(image.shape[0]):\n",
    "        for c in range(image.shape[1]):\n",
    "            if image[r,c] > 0.05:\n",
    "                image[r,c] = 255\n",
    "            else:\n",
    "                image[r,c] = 0\n",
    "\n",
    "    return image\n",
    "\n",
    "def disk_erode(img, radius=24, iters=1):\n",
    "    image = img.copy()\n",
    "    kern_disk = disk(radius)\n",
    "    eroded = cv2.erode(image, kern_disk, iterations=iters)\n",
    "    \n",
    "    return eroded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_DIC():\n",
    "    for filename in fi_list('DIC-C2DH-HeLa/Sequence 1 Masks'):\n",
    "        if not filename.endswith(\".tif\"):\n",
    "            continue\n",
    "        print(filename)\n",
    "        image = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        \n",
    "        cell_mask = (image > 0).astype(np.uint8)\n",
    "        plt.imshow(cell_mask)\n",
    "        plt.show()\n",
    "        \n",
    "        markers = disk_erode(cell_mask)\n",
    "        plt.title(\"Markers\")\n",
    "        plt.imshow(markers)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        blurred = cv2.medianBlur(image, 21)\n",
    "        \n",
    "        denoised = cv2.fastNlMeansDenoising(blurred, h=3)        \n",
    "        \n",
    "        # adaptive normalization - see paper https://is.muni.cz/www/svoboda/ISBI-final.pdf\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        cl1 = clahe.apply(denoised)\n",
    "        \n",
    "        mj_filtered = meijering(cl1)\n",
    "        mj_filtered = custom_thresh(mj_filtered)\n",
    "        \n",
    "        kernel = np.ones((4,4),np.uint8)\n",
    "\n",
    "        eroded = cv2.erode(mj_filtered, kernel, iterations=1)\n",
    "\n",
    "        thresh = cv2.threshold(eroded, 129, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        distance = ndi.distance_transform_edt(thresh)\n",
    "        local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((10, 10)),\n",
    "                                labels=thresh)\n",
    "        markers, _ = ndi.label(local_maxi)\n",
    "        ws_labels = watershed(-distance, markers, mask=thresh)\n",
    "        \n",
    "        plt.gray()\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(blurred)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(denoised)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(cl1)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(mj_filtered)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(eroded)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(thresh, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(ws_labels)\n",
    "        plt.show()\n",
    "        \n",
    "        #break stops loop after one iteration for debugging\n",
    "        break\n",
    "        \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect_Fluo():\n",
    "#     #initialising variables for tracking\n",
    "#     tracker = Tracker(160, 30, 5, 100)\n",
    "#     skip_frame_count = 0\n",
    "#     trackIdCount = 0\n",
    "#     for filename in fi_list('Fluo-N2DL-HeLa/Sequence 1'):\n",
    "#         if not filename.endswith(\".tif\"):\n",
    "#             continue\n",
    "#         # print(filename)\n",
    "#         image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "#         # Threshold at value of 129\n",
    "#         thresh = cv2.threshold(image, 129, 255, cv2.THRESH_BINARY)[1]\n",
    "#         distance = ndi.distance_transform_edt(thresh)\n",
    "#         local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((10, 10)),\n",
    "#                                 labels=thresh)\n",
    "#         markers, _ = ndi.label(local_maxi)\n",
    "#         ws_labels = watershed(-distance, markers, mask=thresh)\n",
    "#         print(len(ws_labels))\n",
    "        \n",
    "#         #TODO: cite/recode following\n",
    "#         # loop over the unique labels returned by the Watershed\n",
    "#         # algorithm\n",
    "#         centers = []\n",
    "#         for label in np.unique(ws_labels):\n",
    "#             # if the label is zero, we are examining the 'background'\n",
    "#             # so simply ignore it\n",
    "#             if label == 0:\n",
    "#                 continue\n",
    "\n",
    "#             # otherwise, allocate memory for the label region and draw\n",
    "#             # it on the mask\n",
    "#             mask = np.zeros(image.shape, dtype=\"uint8\")\n",
    "#             mask[ws_labels == label] = 255\n",
    "\n",
    "#             # detect contours in the mask and grab the largest one\n",
    "#             cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "#                 cv2.CHAIN_APPROX_SIMPLE)\n",
    "#             cnts = imutils.grab_contours(cnts)\n",
    "#             c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "#             # draw a rectangle enclosing the object\n",
    "#             try:\n",
    "#                 x,y,w,h = cv2.boundingRect(c)\n",
    "#                 center = np.array([[int(x + w / 2.0)], [int(y + h / 2.0)]])\n",
    "#                 centers.append(center)\n",
    "#                 # print(bounding_box_center)\n",
    "                \n",
    "#             except ZeroDivisionError:\n",
    "#                 pass\n",
    "#             cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "#             cv2.putText(image, \"#{}\".format(label), (int(x) - 10, int(y)),\n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "#         image = track_path(image,centers,trackIdCount,tracker)\n",
    "#         # plt.gray()\n",
    "#         # plt.imshow(thresh, cmap='gray')\n",
    "#         # plt.show()\n",
    "#         plt.imshow(image)\n",
    "#         plt.show()\n",
    "#     return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_PhC():\n",
    "    pathTracker = PathTracker()\n",
    "    for filename in fi_list('PhC-C2DL-PSC/Sequence 1'):\n",
    "        if not filename.endswith(\".tif\"):\n",
    "            continue\n",
    "        #process images to segment the cells to find labels\n",
    "        ws_lables,image = find_labels(filename)\n",
    "        #Extract the centers of cells detected\n",
    "        centers, boundingBoxes = find_centers(ws_lables,image)\n",
    "        #draw bounding boxes for the detected cells\n",
    "        plot_rectangles(image, centers, boundingBoxes)\n",
    "                    \n",
    "        pathTracker.update(image,centers)\n",
    "#         plt.imshow(opening, cmap='gray')\n",
    "#         plt.show()\n",
    "        # plt.imshow(ws_labels, cmap='gray')\n",
    "        # plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "49\n24\n94\n111\n81\n106\n24\n49\n81\n94\n106\n111\n2\n23\n91\n29\n99\n79\n2\n23\n29\n79\n91\n99\n8\n23\n29\n34\n82\n95\n79\n25\n21\n24\n72\n80\n8\n21\n23\n24\n25\n29\n34\n72\n79\n80\n82\n95\n14\n16\n23\n47\n86\n90\n111\n91\n64\n14\n16\n23\n47\n64\n86\n90\n91\n111\n5\n53\n93\n111\n91\n5\n53\n91\n93\n111\n19\n17\n7\n29\n24\n36\n102\n87\n33\n58\n104\n64\n125\n39\n7\n17\n19\n21\n24\n25\n27\n29\n30\n33\n36\n39\n58\n64\n87\n102\n104\n125\n84\n105\n86\n84\n86\n105\n22\n16\n103\n51\n29\n16\n22\n29\n51\n103\n80\n70\n48\n33\n50\n114\n45\n91\n93\n110\n33\n45\n48\n50\n70\n80\n91\n93\n110\n114\n21\n26\n36\n17\n89\n95\n39\n108\n17\n21\n26\n36\n39\n89\n95\n108\n34\n83\n84\n86\n80\n104\n34\n80\n83\n84\n86\n104\n14\n68\n36\n86\n2\n87\n109\n105\n2\n14\n36\n68\n86\n87\n105\n109\n41\n32\n4\n69\n109\n87\n4\n32\n41\n69\n87\n109\n"
    }
   ],
   "source": [
    "def main():\n",
    "    select = int(input(\"Choose a dataset.\\n1) DIC-C2DH-HeLa\\n2) Fluo-N2DL-HeLa\\n3) PhC-C2DL-PSC\\n> \"))\n",
    "    # select = 3 ##FOR TESTING\n",
    "\n",
    "    if select == 1:\n",
    "        detect_DIC()\n",
    "    elif select == 2:\n",
    "        detect_Fluo()\n",
    "    elif select == 3:\n",
    "        detect_PhC()\n",
    "    else:\n",
    "        print(\"Invalid input.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Vision Project - Group C.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}