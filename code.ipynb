{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l269CuCw_h3J",
    "outputId": "aa7f4f85-ce5a-43c8-99cf-495443ff9298"
   },
   "outputs": [],
   "source": [
    "# %cd /content/drive/My\\ Drive/Colab\\ Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWhdm8qGjDGh"
   },
   "outputs": [],
   "source": [
    "## COMP9517 Computer Vision Project 20T2\n",
    "# code: Main program for the project\n",
    "#\n",
    "# Group C:\n",
    "# Connor Baginski (z5207788)\n",
    "# Bhumika Singhal (z5234799)\n",
    "# Rishav Guha (z5294757)\n",
    "# Amel Johny (z5294308)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "from processing import *\n",
    "from network import Network\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from skimage.morphology import watershed, disk\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.filters import meijering\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from cell_tracking.helpers import fi_list, find_centers, plot_rectangles,find_labels_Phc,find_labels_Fluo,print_tracks,put_text\n",
    "from cell_tracking.pathTracking import PathTracker\n",
    "\n",
    "\n",
    "\n",
    "def fi_list(path):\n",
    "    \"\"\"\n",
    "    Return a sorted list of filenames in a given path\n",
    "    \"\"\"\n",
    "    return sorted([os.path.join(path, f) for f in os.listdir(path)])\n",
    "\n",
    "def plot_two_images(imgL, imgR, titleL, titleR):\n",
    "    f = plt.figure()\n",
    "    f.add_subplot(1,2, 1)\n",
    "    plt.imshow(imgL, cmap='gray')\n",
    "    plt.title(titleL)\n",
    "    f.add_subplot(1,2, 2)\n",
    "    plt.imshow(imgR, cmap='gray')\n",
    "    plt.title(titleR)\n",
    "    plt.show(block=True)\n",
    "\n",
    "def custom_thresh(image):\n",
    "    for r in range(image.shape[0]):\n",
    "        for c in range(image.shape[1]):\n",
    "            if image[r,c] > 0.05:\n",
    "                image[r,c] = 255\n",
    "            else:\n",
    "                image[r,c] = 0\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jgu3dqD1JyY-"
   },
   "outputs": [],
   "source": [
    "def detect_DIC():\n",
    "    pathTracker = PathTracker()\n",
    "    \n",
    "    for filename in fi_list('DIC-C2DH-HeLa/Sequence 3'):\n",
    "        if not filename.endswith(\".tif\"):\n",
    "            continue\n",
    "        print(filename)\n",
    "        image = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "        # Preprocessing\n",
    "        image = equalize_clahe(image)\n",
    "        x = torch.tensor(np.array([image.astype(np.float32)]))\n",
    "        # Add a \"Batch\" dimension\n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        # Load CNN models\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        net = Network()\n",
    "        # TODO: CHANGE TO BEST MODEL\n",
    "#         net.load_state_dict(torch.load(\"CNN_min_loss_dic.pth\", map_location=device))\n",
    "        net.load_state_dict(torch.load(\"CNN_max_score_dic.pth\", map_location=device))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "\n",
    "            # Generate cell mask and markers from image           \n",
    "            output = net(x)\n",
    "            markers = (output[0,0] > 0.5).int()\n",
    "            cell_mask = (output[0,1] > 0.5).int()\n",
    "            \n",
    "#             # Plot output images\n",
    "#             plt.imshow(image, cmap='gray')\n",
    "#             plt.title(\"Input\")\n",
    "#             plt.show()\n",
    "            \n",
    "            plot_two_images(cell_mask, markers, \"Cell Mask\", \"Markers\")\n",
    "            \n",
    "            # Postprocessing\n",
    "            ws_labels = get_ws_from_markers(markers.numpy(), cell_mask.numpy(), 12)\n",
    "            bound_box = get_bound_box_from_ws(image, ws_labels)\n",
    "#             pimg(ws_labels)\n",
    "\n",
    "            centers, boundingBoxes = find_centers(ws_labels, image)\n",
    "            number_of_cells_in_frame = len(centers)\n",
    "            put_text(image, 10,50,\"No of cells : {}\".format(number_of_cells_in_frame))\n",
    "            #update tracker with new positions\n",
    "#             print(centers)\n",
    "            pathTracker.update(image,centers)\n",
    "            plot_rectangles(image,boundingBoxes)\n",
    "\n",
    "            # print tracks\n",
    "            print_tracks(image, pathTracker, number_of_cells_in_frame)\n",
    "#             plt.imshow(bound_box, cmap='gray')\n",
    "#             plt.title(\"Cells with bounding box.\")\n",
    "#             plt.show()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHNueLHxJyZJ"
   },
   "outputs": [],
   "source": [
    "def detect_Fluo():\n",
    "    pathTracker = PathTracker()\n",
    "    \n",
    "    for filename in fi_list('Fluo-N2DL-HeLa/Sequence 1'):\n",
    "        if not filename.endswith(\".tif\"):\n",
    "            continue\n",
    "        print(filename)\n",
    "        image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "        # Threshold at value of 129\n",
    "        thresh = cv2.threshold(image, 129, 255, cv2.THRESH_BINARY)[1]\n",
    "        distance = ndi.distance_transform_edt(thresh)\n",
    "        local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((10, 10)),\n",
    "                                labels=thresh)\n",
    "        markers, _ = ndi.label(local_maxi)\n",
    "        ws_labels = watershed(-distance, markers, mask=thresh)\n",
    "        \n",
    "        #TODO: cite/recode following\n",
    "        # loop over the unique labels returned by the Watershed\n",
    "        # algorithm\n",
    "        for label in np.unique(ws_labels):\n",
    "            # if the label is zero, we are examining the 'background'\n",
    "            # so simply ignore it\n",
    "            if label == 0:\n",
    "                continue\n",
    "\n",
    "            # otherwise, allocate memory for the label region and draw\n",
    "            # it on the mask\n",
    "            mask = np.zeros(image.shape, dtype=\"uint8\")\n",
    "            mask[ws_labels == label] = 255\n",
    "\n",
    "            # detect contours in the mask and grab the largest one\n",
    "            cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "                cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnts = imutils.grab_contours(cnts)\n",
    "            c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "            # draw a rectangle enclosing the object\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "#             cv2.putText(image, \"#{}\".format(label), (int(x) - 10, int(y)),\n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        \n",
    "        plt.gray()\n",
    "        plt.imshow(thresh, cmap='gray')\n",
    "        plt.show()\n",
    "#         plt.imshow(image)\n",
    "#         plt.show()\n",
    "        centers, boundingBoxes = find_centers(ws_labels, image)\n",
    "        number_of_cells_in_frame = len(centers)\n",
    "        put_text(image, 10,50,\"No of cells : {}\".format(number_of_cells_in_frame))\n",
    "        #update tracker with new positions\n",
    "#             print(centers)\n",
    "        pathTracker.update(image,centers)\n",
    "        plot_rectangles(image,boundingBoxes)\n",
    "        \n",
    "        # print tracks\n",
    "        print_tracks(image, pathTracker, number_of_cells_in_frame)\n",
    "\n",
    "    return\n",
    "\n",
    "def detect_PhC():\n",
    "    pathTracker = PathTracker()\n",
    "    \n",
    "    for filename in fi_list(r'PhC-C2DL-PSC/Sequence 1'):\n",
    "        if not filename.endswith(\".tif\"):\n",
    "            continue\n",
    "        print(filename)\n",
    "        image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Preprocessing\n",
    "        image = equalize_clahe(image)\n",
    "        x = torch.tensor(np.array([image.astype(np.float32)]))\n",
    "        # Add a \"Batch\" dimension\n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        # Load CNN models\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        net = Network()\n",
    "        # TODO: CHANGE TO BEST MODEL\n",
    "        net.load_state_dict(torch.load(\"CNN_min_loss_phc.pth\", map_location=device))\n",
    "#         net.load_state_dict(torch.load(\"CNN_max_score_phc.pth\", map_location=device))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "\n",
    "            # Generate cell mask and markers from image           \n",
    "            output = net(x)\n",
    "\n",
    "            markers = (output[0,0] > 0.5).int()\n",
    "            cell_mask = (output[0,1] > 0.5).int()\n",
    "            \n",
    "#             # Plot output images\n",
    "#             plt.imshow(image, cmap='gray')\n",
    "#             plt.title(\"Input\")\n",
    "#             plt.show()\n",
    "            \n",
    "#             plot_two_images(cell_mask, markers, \"Cell Mask\", \"Markers\")\n",
    "            \n",
    "            # Postprocessing\n",
    "            ws_labels = get_ws_from_markers(markers.numpy(), cell_mask.numpy(), 0)\n",
    "            bound_box = get_bound_box_from_ws(image, ws_labels)\n",
    "#             pimg(ws_labels)\n",
    "\n",
    "            centers, boundingBoxes = find_centers(ws_labels, image)\n",
    "            number_of_cells_in_frame = len(centers)\n",
    "            put_text(image, 10,50,\"No of cells : {}\".format(number_of_cells_in_frame))\n",
    "            #update tracker with new positions\n",
    "#             print(centers)\n",
    "            pathTracker.update(image,centers)\n",
    "            plot_rectangles(image,boundingBoxes)\n",
    "            \n",
    "            pimg(image)\n",
    "            \n",
    "            # print tracks \n",
    "            print_tracks(image, pathTracker, number_of_cells_in_frame)\n",
    "            \n",
    "#             plt.imshow(bound_box, cmap='gray')\n",
    "#             plt.title(\"Cells with bounding box.\")\n",
    "#             plt.show()\n",
    "            \n",
    "    return\n",
    "        \n",
    "#         thresh = cv2.threshold(image, 162, 255, cv2.THRESH_BINARY)[1]\n",
    "#         kernel = np.ones((4,4),np.uint8)\n",
    "#         # Perform an erosion followed by dilation opening to remove noise\n",
    "#         opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "#         distance = ndi.distance_transform_edt(opening)\n",
    "#         local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((10, 10)),\n",
    "#                                 labels=thresh)\n",
    "#         markers, _ = ndi.label(local_maxi)\n",
    "#         ws_labels = watershed(-distance, markers, mask=thresh)\n",
    "        \n",
    "#         #TODO: cite/recode following\n",
    "#         # loop over the unique labels returned by the Watershed\n",
    "#         # algorithm\n",
    "#         for label in np.unique(ws_labels):\n",
    "#             # if the label is zero, we are examining the 'background'\n",
    "#             # so simply ignore it\n",
    "#             if label == 0:\n",
    "#                 continue\n",
    "\n",
    "#             # otherwise, allocate memory for the label region and draw\n",
    "#             # it on the mask\n",
    "#             mask = np.zeros(image.shape, dtype=\"uint8\")\n",
    "#             mask[ws_labels == label] = 255\n",
    "\n",
    "#             # detect contours in the mask and grab the largest one\n",
    "#             cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "#                 cv2.CHAIN_APPROX_SIMPLE)\n",
    "#             cnts = imutils.grab_contours(cnts)\n",
    "#             c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "#             # draw a rectangle enclosing the object\n",
    "#             x,y,w,h = cv2.boundingRect(c)\n",
    "#             cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "#             cv2.putText(image, \"#{}\".format(label), (int(x) - 10, int(y)),\n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        \n",
    "#         plt.imshow(image, cmap='gray')\n",
    "#         plt.show()\n",
    "#         plt.imshow(opening, cmap='gray')\n",
    "#         plt.show()\n",
    "#         plt.imshow(ws_labels, cmap='gray')\n",
    "#         plt.show()\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "1KPSxTV8JyZR",
    "outputId": "d4df7e1b-6c78-4af3-e1fc-da02e9254edf",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    select = int(input(\"Choose a dataset.\\n1) DIC-C2DH-HeLa\\n2) Fluo-N2DL-HeLa\\n3) PhC-C2DL-PSC\\n> \"))\n",
    "\n",
    "    if select == 1:\n",
    "        detect_DIC()\n",
    "    elif select == 2:\n",
    "        detect_Fluo()\n",
    "    elif select == 3:\n",
    "        detect_PhC()\n",
    "    else:\n",
    "        print(\"Invalid input.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pd2yoG6p4ixl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "code.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('compvis': conda)",
   "language": "python",
   "name": "python38364bitcompvisconda46954d3d832c4b2f84bde7a1c3a50552"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
