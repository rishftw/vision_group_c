{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWhdm8qGjDGh"
   },
   "outputs": [],
   "source": [
    "## COMP9517 Computer Vision Project 20T2\n",
    "# code: Main program for the project\n",
    "#\n",
    "# Group C:\n",
    "# Connor Baginski (z5207788)\n",
    "# Bhumika Singhal (z5234799)\n",
    "# Rishav Guha (z5294757)\n",
    "# Amel Johny (z5294308)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "import preprocessing\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from skimage.morphology import watershed, disk\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.filters import meijering\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "\n",
    "def fi_list(path):\n",
    "    \"\"\"\n",
    "    Return a sorted list of filenames in a given path\n",
    "    \"\"\"\n",
    "    return sorted([os.path.join(path, f) for f in os.listdir(path)])\n",
    "\n",
    "def plot_two_images(imgL, imgR, titleL, titleR):\n",
    "    f = plt.figure()\n",
    "    f.add_subplot(1,2, 1)\n",
    "    plt.imshow(imgL, cmap='gray')\n",
    "    plt.title(titleL)\n",
    "    f.add_subplot(1,2, 2)\n",
    "    plt.imshow(imgR, cmap='gray')\n",
    "    plt.title(titleR)\n",
    "    plt.show(block=True)\n",
    "\n",
    "def custom_thresh(image):\n",
    "    for r in range(image.shape[0]):\n",
    "        for c in range(image.shape[1]):\n",
    "            if image[r,c] > 0.05:\n",
    "                image[r,c] = 255\n",
    "            else:\n",
    "                image[r,c] = 0\n",
    "\n",
    "    return image\n",
    "\n",
    "# Class for creating the CNN\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv11 = nn.Conv2d(768, 256, 3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(384, 128, 3, padding=1)\n",
    "        self.conv14 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv15 = nn.Conv2d(192, 64, 3, padding=1)\n",
    "        self.conv16 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv17 = nn.Conv2d(96, 32, 3, padding=1)\n",
    "        self.conv18 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv_out = nn.Conv2d(32, 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv1(x))\n",
    "        contraction_32 = F.relu(self.conv2(x))\n",
    "        \n",
    "        x = F.max_pool2d(contraction_32, kernel_size=2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        contraction_64 = F.relu(self.conv4(x))\n",
    "        \n",
    "        x = F.max_pool2d(contraction_64, kernel_size=2)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        contraction_128 = F.relu(self.conv6(x))\n",
    "        \n",
    "        x = F.max_pool2d(contraction_128, kernel_size=2)\n",
    "        x = F.relu(self.conv7(x))\n",
    "        contraction_256 = F.relu(self.conv8(x))\n",
    "        \n",
    "        x = F.max_pool2d(contraction_256, kernel_size=2)\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = F.relu(self.conv10(x))\n",
    "        \n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        x = torch.cat((contraction_256, x), dim=1)\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv12(x))\n",
    "        \n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        x = torch.cat((contraction_128, x), dim=1)\n",
    "        x = F.relu(self.conv13(x))\n",
    "        x = F.relu(self.conv14(x))\n",
    "        \n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        x = torch.cat((contraction_64, x), dim=1)\n",
    "        x = F.relu(self.conv15(x))\n",
    "        x = F.relu(self.conv16(x))\n",
    "        \n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        x = torch.cat((contraction_32, x), dim=1)\n",
    "        x = F.relu(self.conv17(x))\n",
    "        x = F.relu(self.conv18(x))\n",
    "        \n",
    "        x = self.conv_out(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_DIC():\n",
    "    for filename in fi_list('DIC-C2DH-HeLa/Sequence 3'):\n",
    "        if not filename.endswith(\".tif\"):\n",
    "            continue\n",
    "        print(filename)\n",
    "        image = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "        # Preprocessing\n",
    "        image = preprocessing.equalize_clahe(image).astype(np.float32)\n",
    "        image = torch.tensor(np.array([image]))\n",
    "        print(image.shape)\n",
    "        # Add a \"Batch\" dimension\n",
    "        image = image.unsqueeze(0)\n",
    "        print(image.shape)\n",
    "        \n",
    "        # Load CNN models\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        net_c, net_m = Network(), Network()\n",
    "        net_c.load_state_dict(torch.load(\"CNN_c.pth\", map_location=device))\n",
    "        net_m.load_state_dict(torch.load(\"CNN_m.pth\", map_location=device))\n",
    "        \n",
    "        # Generate cell mask and markers from image\n",
    "        net_c.eval()\n",
    "        output_c = net_c(image)\n",
    "        cell_mask = torch.argmax(output_c, dim=0).cpu()\n",
    "        \n",
    "        net_m.eval()\n",
    "        output_m = net_m(image)\n",
    "        markers = torch.argmax(output_m, dim=0).cpu()\n",
    "        \n",
    "        # Plot images\n",
    "        plt.imshow(x[0][0].cpu(), cmap='gray')\n",
    "        plt.title(\"Input\")\n",
    "        plt.show()\n",
    "        \n",
    "        plot_two_images(cell_mask, markers, \"Cell Mask\", \"Markers\")\n",
    "        \n",
    "        # Postprocessing\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_Fluo():\n",
    "    for filename in fi_list('Fluo-N2DL-HeLa/Sequence 1'):\n",
    "        if not filename.endswith(\".tif\"):\n",
    "            continue\n",
    "        print(filename)\n",
    "        image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "        # Threshold at value of 129\n",
    "        thresh = cv2.threshold(image, 129, 255, cv2.THRESH_BINARY)[1]\n",
    "        distance = ndi.distance_transform_edt(thresh)\n",
    "        local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((10, 10)),\n",
    "                                labels=thresh)\n",
    "        markers, _ = ndi.label(local_maxi)\n",
    "        ws_labels = watershed(-distance, markers, mask=thresh)\n",
    "        \n",
    "        #TODO: cite/recode following\n",
    "        # loop over the unique labels returned by the Watershed\n",
    "        # algorithm\n",
    "        for label in np.unique(ws_labels):\n",
    "            # if the label is zero, we are examining the 'background'\n",
    "            # so simply ignore it\n",
    "            if label == 0:\n",
    "                continue\n",
    "\n",
    "            # otherwise, allocate memory for the label region and draw\n",
    "            # it on the mask\n",
    "            mask = np.zeros(image.shape, dtype=\"uint8\")\n",
    "            mask[ws_labels == label] = 255\n",
    "\n",
    "            # detect contours in the mask and grab the largest one\n",
    "            cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "                cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnts = imutils.grab_contours(cnts)\n",
    "            c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "            # draw a rectangle enclosing the object\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.putText(image, \"#{}\".format(label), (int(x) - 10, int(y)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        \n",
    "        plt.gray()\n",
    "        plt.imshow(thresh, cmap='gray')\n",
    "        plt.show()\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "    return\n",
    "\n",
    "def detect_PhC():\n",
    "    for filename in fi_list('PhC-C2DL-PSC/Sequence 1'):\n",
    "        if not filename.endswith(\".tif\"):\n",
    "            continue\n",
    "        print(filename)\n",
    "        image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "        thresh = cv2.threshold(image, 162, 255, cv2.THRESH_BINARY)[1]\n",
    "        kernel = np.ones((4,4),np.uint8)\n",
    "        # Perform an erosion followed by dilation opening to remove noise\n",
    "        opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "        distance = ndi.distance_transform_edt(opening)\n",
    "        local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((10, 10)),\n",
    "                                labels=thresh)\n",
    "        markers, _ = ndi.label(local_maxi)\n",
    "        ws_labels = watershed(-distance, markers, mask=thresh)\n",
    "        \n",
    "        #TODO: cite/recode following\n",
    "        # loop over the unique labels returned by the Watershed\n",
    "        # algorithm\n",
    "        for label in np.unique(ws_labels):\n",
    "            # if the label is zero, we are examining the 'background'\n",
    "            # so simply ignore it\n",
    "            if label == 0:\n",
    "                continue\n",
    "\n",
    "            # otherwise, allocate memory for the label region and draw\n",
    "            # it on the mask\n",
    "            mask = np.zeros(image.shape, dtype=\"uint8\")\n",
    "            mask[ws_labels == label] = 255\n",
    "\n",
    "            # detect contours in the mask and grab the largest one\n",
    "            cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "                cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnts = imutils.grab_contours(cnts)\n",
    "            c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "            # draw a rectangle enclosing the object\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.putText(image, \"#{}\".format(label), (int(x) - 10, int(y)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        \n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.show()\n",
    "        plt.imshow(opening, cmap='gray')\n",
    "        plt.show()\n",
    "        plt.imshow(ws_labels, cmap='gray')\n",
    "        plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose a dataset.\n",
      "1) DIC-C2DH-HeLa\n",
      "2) Fluo-N2DL-HeLa\n",
      "3) PhC-C2DL-PSC\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIC-C2DH-HeLa/Sequence 3/t000.tif\n",
      "torch.Size([1, 512, 512])\n",
      "torch.Size([1, 1, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arc/.local/lib/python3.7/site-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8dafb536f42a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-8dafb536f42a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mselect\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdetect_DIC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mselect\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdetect_Fluo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-5c4f2117e94b>\u001b[0m in \u001b[0;36mdetect_DIC\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Plot images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    select = int(input(\"Choose a dataset.\\n1) DIC-C2DH-HeLa\\n2) Fluo-N2DL-HeLa\\n3) PhC-C2DL-PSC\\n> \"))\n",
    "\n",
    "    if select == 1:\n",
    "        detect_DIC()\n",
    "    elif select == 2:\n",
    "        detect_Fluo()\n",
    "    elif select == 3:\n",
    "        detect_PhC()\n",
    "    else:\n",
    "        print(\"Invalid input.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Vision Project - Group C.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
