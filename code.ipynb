{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWhdm8qGjDGh"
   },
   "outputs": [],
   "source": [
    "## COMP9517 Computer Vision Project 20T2\n",
    "#\n",
    "# Group C:\n",
    "# Connor Baginski (z5207788)\n",
    "# Bhumika Singhal (z5234799)\n",
    "# Rishav Guha (z5294757)\n",
    "# Amel Johny (z5294308)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max, canny\n",
    "from skimage.filters import meijering, sato\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "\n",
    "def fi_list(path):\n",
    "    \"\"\"\n",
    "    Return a sorted list of filenames in a given path\n",
    "    \"\"\"\n",
    "    return sorted([os.path.join(path, f) for f in os.listdir(path)])\n",
    "\n",
    "def custom_thresh(image):\n",
    "    for r in range(image.shape[0]):\n",
    "        for c in range(image.shape[1]):\n",
    "            if image[r,c] > 0.05:\n",
    "                image[r,c] = 255\n",
    "            else:\n",
    "                image[r,c] = 0\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for creating the CNN\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.net = nn.Conv2d(1, 1, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network\n",
    "        \"\"\"\n",
    "        return self.net(x)\n",
    "    \n",
    "\n",
    "def lossFunction():\n",
    "    \"\"\"\n",
    "    TODO: Implement the Weighted Mean Square Error loss function as per ISBI-final paper\n",
    "    Currently using Mean Square Error loss\n",
    "    \"\"\"\n",
    "    return F.mse_loss\n",
    "\n",
    "def train_net():\n",
    "    \"\"\"\n",
    "    Train the network on data and save the model\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    net = Network().to(device)\n",
    "    optimiser = optim.Adam(net.parameters(), lr=0.001) # optimising using Adam algorithm\n",
    "    criterion = lossFunction()\n",
    "    \n",
    "    # Iterate over a number of epochs on the data\n",
    "    for epoch in range(10):\n",
    "        # TODO: perform training step\n",
    "        print(f\"Epoch: {epoch+1}\")\n",
    "    \n",
    "    torch.save(net.state_dict(), \"./model.pth\")\n",
    "    print(\"Saved model\")\n",
    "\n",
    "\n",
    "train = input(\"Train Network? y/n\\n> \")\n",
    "if train.lower() == \"y\":\n",
    "    train_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_DIC():\n",
    "    for filename in fi_list('DIC-C2DH-HeLa/Sequence 1'):\n",
    "        if not filename.endswith(\".tif\"):\n",
    "            continue\n",
    "        print(filename)\n",
    "        image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        blurred = cv2.medianBlur(image, 21)\n",
    "        \n",
    "        denoised = cv2.fastNlMeansDenoising(blurred, h=3)        \n",
    "        \n",
    "        # adaptive normalization - see paper https://is.muni.cz/www/svoboda/ISBI-final.pdf\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        cl1 = clahe.apply(denoised)\n",
    "        \n",
    "        mj_filtered = meijering(cl1)\n",
    "        mj_filtered = custom_thresh(mj_filtered)\n",
    "        \n",
    "        kernel = np.ones((4,4),np.uint8)\n",
    "\n",
    "        eroded = cv2.erode(mj_filtered, kernel, iterations=1)\n",
    "\n",
    "        thresh = cv2.threshold(eroded, 129, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        distance = ndi.distance_transform_edt(thresh)\n",
    "        local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((10, 10)),\n",
    "                                labels=thresh)\n",
    "        markers, _ = ndi.label(local_maxi)\n",
    "        ws_labels = watershed(-distance, markers, mask=thresh)\n",
    "        \n",
    "        plt.gray()\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(blurred)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(denoised)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(cl1)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(mj_filtered)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(eroded)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(thresh, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(ws_labels)\n",
    "        plt.show()\n",
    "        \n",
    "        #break stops loop after one iteration for debugging\n",
    "        break\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_Fluo():\n",
    "    for filename in fi_list('Fluo-N2DL-HeLa/Sequence 1'):\n",
    "        if not filename.endswith(\".tif\"):\n",
    "            continue\n",
    "        print(filename)\n",
    "        image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "        # Threshold at value of 129\n",
    "        thresh = cv2.threshold(image, 129, 255, cv2.THRESH_BINARY)[1]\n",
    "        distance = ndi.distance_transform_edt(thresh)\n",
    "        local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((10, 10)),\n",
    "                                labels=thresh)\n",
    "        markers, _ = ndi.label(local_maxi)\n",
    "        ws_labels = watershed(-distance, markers, mask=thresh)\n",
    "        \n",
    "        #TODO: cite/recode following\n",
    "        # loop over the unique labels returned by the Watershed\n",
    "        # algorithm\n",
    "        for label in np.unique(ws_labels):\n",
    "            # if the label is zero, we are examining the 'background'\n",
    "            # so simply ignore it\n",
    "            if label == 0:\n",
    "                continue\n",
    "\n",
    "            # otherwise, allocate memory for the label region and draw\n",
    "            # it on the mask\n",
    "            mask = np.zeros(image.shape, dtype=\"uint8\")\n",
    "            mask[ws_labels == label] = 255\n",
    "\n",
    "            # detect contours in the mask and grab the largest one\n",
    "            cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "                cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnts = imutils.grab_contours(cnts)\n",
    "            c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "            # draw a rectangle enclosing the object\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.putText(image, \"#{}\".format(label), (int(x) - 10, int(y)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        \n",
    "        plt.gray()\n",
    "        plt.imshow(thresh, cmap='gray')\n",
    "        plt.show()\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "    return\n",
    "\n",
    "def detect_PhC():\n",
    "    for filename in fi_list('PhC-C2DL-PSC/Sequence 1'):\n",
    "        if not filename.endswith(\".tif\"):\n",
    "            continue\n",
    "        print(filename)\n",
    "        image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "        thresh = cv2.threshold(image, 162, 255, cv2.THRESH_BINARY)[1]\n",
    "        kernel = np.ones((4,4),np.uint8)\n",
    "        # Perform an erosion followed by dilation opening to remove noise\n",
    "        opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "        distance = ndi.distance_transform_edt(opening)\n",
    "        local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((10, 10)),\n",
    "                                labels=thresh)\n",
    "        markers, _ = ndi.label(local_maxi)\n",
    "        ws_labels = watershed(-distance, markers, mask=thresh)\n",
    "        \n",
    "        #TODO: cite/recode following\n",
    "        # loop over the unique labels returned by the Watershed\n",
    "        # algorithm\n",
    "        for label in np.unique(ws_labels):\n",
    "            # if the label is zero, we are examining the 'background'\n",
    "            # so simply ignore it\n",
    "            if label == 0:\n",
    "                continue\n",
    "\n",
    "            # otherwise, allocate memory for the label region and draw\n",
    "            # it on the mask\n",
    "            mask = np.zeros(image.shape, dtype=\"uint8\")\n",
    "            mask[ws_labels == label] = 255\n",
    "\n",
    "            # detect contours in the mask and grab the largest one\n",
    "            cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "                cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnts = imutils.grab_contours(cnts)\n",
    "            c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "            # draw a rectangle enclosing the object\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.putText(image, \"#{}\".format(label), (int(x) - 10, int(y)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        \n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.show()\n",
    "        plt.imshow(opening, cmap='gray')\n",
    "        plt.show()\n",
    "        plt.imshow(ws_labels, cmap='gray')\n",
    "        plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    select = int(input(\"Choose a dataset.\\n1) DIC-C2DH-HeLa\\n2) Fluo-N2DL-HeLa\\n3) PhC-C2DL-PSC\\n> \"))\n",
    "\n",
    "    if select == 1:\n",
    "        detect_DIC()\n",
    "    elif select == 2:\n",
    "        detect_Fluo()\n",
    "    elif select == 3:\n",
    "        detect_PhC()\n",
    "    else:\n",
    "        print(\"Invalid input.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Vision Project - Group C.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
