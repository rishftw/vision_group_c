{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uWhdm8qGjDGh",
        "colab": {}
      },
      "source": [
        "## COMP9517 Computer Vision Project 20T2\n",
        "# code: Main program for the project\n",
        "#\n",
        "# Group C:\n",
        "# Connor Baginski (z5207788)\n",
        "# Bhumika Singhal (z5234799)\n",
        "# Rishav Guha (z5294757)\n",
        "# Amel Johny (z5294308)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import imutils\n",
        "from processing import *\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from skimage.morphology import watershed, disk\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage.filters import meijering\n",
        "\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "\n",
        "def fi_list(path):\n",
        "    \"\"\"\n",
        "    Return a sorted list of filenames in a given path\n",
        "    \"\"\"\n",
        "    return sorted([os.path.join(path, f) for f in os.listdir(path)])\n",
        "\n",
        "def plot_two_images(imgL, imgR, titleL, titleR):\n",
        "    f = plt.figure()\n",
        "    f.add_subplot(1,2, 1)\n",
        "    plt.imshow(imgL, cmap='gray')\n",
        "    plt.title(titleL)\n",
        "    f.add_subplot(1,2, 2)\n",
        "    plt.imshow(imgR, cmap='gray')\n",
        "    plt.title(titleR)\n",
        "    plt.show(block=True)\n",
        "\n",
        "def custom_thresh(image):\n",
        "    for r in range(image.shape[0]):\n",
        "        for c in range(image.shape[1]):\n",
        "            if image[r,c] > 0.05:\n",
        "                image[r,c] = 255\n",
        "            else:\n",
        "                image[r,c] = 0\n",
        "\n",
        "    return image\n",
        "\n",
        "# Class for creating the CNN\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.conv7 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv8 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.conv9 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.conv10 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv11 = nn.Conv2d(768, 256, 3, padding=1)\n",
        "        self.conv12 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.conv13 = nn.Conv2d(384, 128, 3, padding=1)\n",
        "        self.conv14 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.conv15 = nn.Conv2d(192, 64, 3, padding=1)\n",
        "        self.conv16 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.conv17 = nn.Conv2d(96, 32, 3, padding=1)\n",
        "        self.conv18 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.conv_out = nn.Conv2d(32, 2, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the network\n",
        "        \"\"\"\n",
        "        x = F.relu(self.conv1(x))\n",
        "        contraction_32 = F.relu(self.conv2(x))\n",
        "        \n",
        "        x = F.max_pool2d(contraction_32, kernel_size=2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        contraction_64 = F.relu(self.conv4(x))\n",
        "        \n",
        "        x = F.max_pool2d(contraction_64, kernel_size=2)\n",
        "        x = F.relu(self.conv5(x))\n",
        "        contraction_128 = F.relu(self.conv6(x))\n",
        "        \n",
        "        x = F.max_pool2d(contraction_128, kernel_size=2)\n",
        "        x = F.relu(self.conv7(x))\n",
        "        contraction_256 = F.relu(self.conv8(x))\n",
        "        \n",
        "        x = F.max_pool2d(contraction_256, kernel_size=2)\n",
        "        x = F.relu(self.conv9(x))\n",
        "        x = F.relu(self.conv10(x))\n",
        "        \n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
        "        x = torch.cat((contraction_256, x), dim=1)\n",
        "        x = F.relu(self.conv11(x))\n",
        "        x = F.relu(self.conv12(x))\n",
        "        \n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
        "        x = torch.cat((contraction_128, x), dim=1)\n",
        "        x = F.relu(self.conv13(x))\n",
        "        x = F.relu(self.conv14(x))\n",
        "        \n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
        "        x = torch.cat((contraction_64, x), dim=1)\n",
        "        x = F.relu(self.conv15(x))\n",
        "        x = F.relu(self.conv16(x))\n",
        "        \n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
        "        x = torch.cat((contraction_32, x), dim=1)\n",
        "        x = F.relu(self.conv17(x))\n",
        "        x = F.relu(self.conv18(x))\n",
        "        \n",
        "        x = self.conv_out(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgu3dqD1JyY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_DIC():\n",
        "    for filename in fi_list('DIC-C2DH-HeLa/Sequence 3'):\n",
        "        if not filename.endswith(\".tif\"):\n",
        "            continue\n",
        "        print(filename)\n",
        "        image = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
        "        # Preprocessing\n",
        "        image = equalize_clahe(image)\n",
        "        x = torch.tensor(np.array([image.astype(np.float32)]))\n",
        "        # Add a \"Batch\" dimension\n",
        "        x = x.unsqueeze(0)\n",
        "        \n",
        "        # Load CNN models\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        net_c, net_m = Network(), Network()\n",
        "        net_c.load_state_dict(torch.load(\"CNN_c.pth\", map_location=device))\n",
        "        net_m.load_state_dict(torch.load(\"CNN_m.pth\", map_location=device))\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # Generate cell mask and markers from image\n",
        "            net_c.eval()\n",
        "            output_c = net_c(x)\n",
        "            cell_mask = torch.argmax(output_c[0], dim=0).cpu()\n",
        "            \n",
        "            net_m.eval()\n",
        "            output_m = net_m(x)\n",
        "            markers = torch.argmax(output_m[0], dim=0).cpu()\n",
        "            \n",
        "            # Plot output images\n",
        "            plt.imshow(image, cmap='gray')\n",
        "            plt.title(\"Input\")\n",
        "            plt.show()\n",
        "            \n",
        "            plot_two_images(cell_mask, markers, \"Cell Mask\", \"Markers\")\n",
        "            \n",
        "            # Postprocessing\n",
        "            ws_labels = get_ws_from_markers(markers.numpy(), cell_mask.numpy())\n",
        "            bound_box = get_bound_box_from_ws(image, ws_labels)\n",
        "\n",
        "            plt.imshow(bound_box, cmap='gray')\n",
        "            plt.title(\"Cells with bounding box.\")\n",
        "            plt.show()\n",
        "        \n",
        "    return"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHNueLHxJyZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_Fluo():\n",
        "    for filename in fi_list('Fluo-N2DL-HeLa/Sequence 1'):\n",
        "        if not filename.endswith(\".tif\"):\n",
        "            continue\n",
        "        print(filename)\n",
        "        image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
        "        # Threshold at value of 129\n",
        "        thresh = cv2.threshold(image, 129, 255, cv2.THRESH_BINARY)[1]\n",
        "        distance = ndi.distance_transform_edt(thresh)\n",
        "        local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((10, 10)),\n",
        "                                labels=thresh)\n",
        "        markers, _ = ndi.label(local_maxi)\n",
        "        ws_labels = watershed(-distance, markers, mask=thresh)\n",
        "        \n",
        "        #TODO: cite/recode following\n",
        "        # loop over the unique labels returned by the Watershed\n",
        "        # algorithm\n",
        "        for label in np.unique(ws_labels):\n",
        "            # if the label is zero, we are examining the 'background'\n",
        "            # so simply ignore it\n",
        "            if label == 0:\n",
        "                continue\n",
        "\n",
        "            # otherwise, allocate memory for the label region and draw\n",
        "            # it on the mask\n",
        "            mask = np.zeros(image.shape, dtype=\"uint8\")\n",
        "            mask[ws_labels == label] = 255\n",
        "\n",
        "            # detect contours in the mask and grab the largest one\n",
        "            cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
        "                cv2.CHAIN_APPROX_SIMPLE)\n",
        "            cnts = imutils.grab_contours(cnts)\n",
        "            c = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "            # draw a rectangle enclosing the object\n",
        "            x,y,w,h = cv2.boundingRect(c)\n",
        "            cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
        "            cv2.putText(image, \"#{}\".format(label), (int(x) - 10, int(y)),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
        "        \n",
        "        plt.gray()\n",
        "        plt.imshow(thresh, cmap='gray')\n",
        "        plt.show()\n",
        "        plt.imshow(image)\n",
        "        plt.show()\n",
        "    return\n",
        "\n",
        "def detect_PhC():\n",
        "    for filename in fi_list('PhC-C2DL-PSC/Sequence 1'):\n",
        "        if not filename.endswith(\".tif\"):\n",
        "            continue\n",
        "        print(filename)\n",
        "        image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
        "        thresh = cv2.threshold(image, 162, 255, cv2.THRESH_BINARY)[1]\n",
        "        kernel = np.ones((4,4),np.uint8)\n",
        "        # Perform an erosion followed by dilation opening to remove noise\n",
        "        opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "        distance = ndi.distance_transform_edt(opening)\n",
        "        local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((10, 10)),\n",
        "                                labels=thresh)\n",
        "        markers, _ = ndi.label(local_maxi)\n",
        "        ws_labels = watershed(-distance, markers, mask=thresh)\n",
        "        \n",
        "        #TODO: cite/recode following\n",
        "        # loop over the unique labels returned by the Watershed\n",
        "        # algorithm\n",
        "        for label in np.unique(ws_labels):\n",
        "            # if the label is zero, we are examining the 'background'\n",
        "            # so simply ignore it\n",
        "            if label == 0:\n",
        "                continue\n",
        "\n",
        "            # otherwise, allocate memory for the label region and draw\n",
        "            # it on the mask\n",
        "            mask = np.zeros(image.shape, dtype=\"uint8\")\n",
        "            mask[ws_labels == label] = 255\n",
        "\n",
        "            # detect contours in the mask and grab the largest one\n",
        "            cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
        "                cv2.CHAIN_APPROX_SIMPLE)\n",
        "            cnts = imutils.grab_contours(cnts)\n",
        "            c = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "            # draw a rectangle enclosing the object\n",
        "            x,y,w,h = cv2.boundingRect(c)\n",
        "            cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
        "            cv2.putText(image, \"#{}\".format(label), (int(x) - 10, int(y)),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
        "        \n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.show()\n",
        "        plt.imshow(opening, cmap='gray')\n",
        "        plt.show()\n",
        "        plt.imshow(ws_labels, cmap='gray')\n",
        "        plt.show()\n",
        "    return"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "1KPSxTV8JyZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    select = int(input(\"Choose a dataset.\\n1) DIC-C2DH-HeLa\\n2) Fluo-N2DL-HeLa\\n3) PhC-C2DL-PSC\\n> \"))\n",
        "\n",
        "    if select == 1:\n",
        "        detect_DIC()\n",
        "    elif select == 2:\n",
        "        detect_Fluo()\n",
        "    elif select == 3:\n",
        "        detect_PhC()\n",
        "    else:\n",
        "        print(\"Invalid input.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}