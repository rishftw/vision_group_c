{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5thgoDohupI"
   },
   "outputs": [],
   "source": [
    "# %cd drive/My\\ Drive/Colab\\ Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bzxi4RNilhNj"
   },
   "outputs": [],
   "source": [
    "# train_networks: Training CNN to be used by the main program\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "from processing import *\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.morphology import disk\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.filters import meijering\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "BATCH_SIZE = 3\n",
    "IMAGES_LIMIT = 2000\n",
    "\n",
    "def plot_two_images(imgL, imgR, titleL, titleR):\n",
    "    f = plt.figure()\n",
    "    f.add_subplot(1,2, 1)\n",
    "    plt.imshow(imgL, cmap='gray')\n",
    "    plt.title(titleL)\n",
    "    f.add_subplot(1,2, 2)\n",
    "    plt.imshow(imgR, cmap='gray')\n",
    "    plt.title(titleR)\n",
    "    plt.show(block=True)\n",
    "    \n",
    "\n",
    "# def load_data(dataset):\n",
    "#     data = []\n",
    "#     paths = [os.path.join(dataset, '01'), os.path.join(dataset, '02')]\n",
    "#     for path in paths:\n",
    "#         mask_path = path + '_ST'\n",
    "#         mask_path = os.path.join(mask_path, 'SEG')\n",
    "#         for f in os.listdir(mask_path):\n",
    "#             if not f.endswith(\".tif\"):\n",
    "#                 continue\n",
    "#             image = cv2.imread(os.path.join(path, f.replace('man_seg', 't')), cv2.IMREAD_GRAYSCALE)\n",
    "#             image = equalize_clahe(image).astype(np.float32)\n",
    "#             mask = cv2.imread(os.path.join(mask_path, f), cv2.IMREAD_UNCHANGED)\n",
    "#             print(\"   Loaded \" + os.path.join(mask_path, f) + \", \" + os.path.join(path, f.replace('man_seg', 't')))\n",
    "            \n",
    "#             # Generate the Cell Mask and Markers from the Mask\n",
    "#             cell_mask = (mask > 0).astype(np.uint8)\n",
    "#             markers = (get_markers(mask) > 0).astype(np.uint8)\n",
    "#             weight_map = get_weight_map(markers)\n",
    "            \n",
    "#             # Pack the data for the DataLoader\n",
    "#             target = (cell_mask, markers, weight_map)\n",
    "#             data.append((np.array([image]), target))\n",
    "\n",
    "#     train_size = int(0.8 * len(data))\n",
    "#     test_size = len(data) - train_size\n",
    "#     train_data, test_data = random_split(data, [train_size, test_size])\n",
    "#     trainLoader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "#     testLoader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "#     return trainLoader, testLoader\n",
    "\n",
    "def load_data(dataset):\n",
    "    data = []\n",
    "    path = os.path.join(dataset, \"originals\")\n",
    "    clahe_path = path.replace(\"originals\", \"clahes\")\n",
    "    mask_path = path.replace(\"originals\", \"masks\")\n",
    "    markers_path = path.replace(\"originals\", \"markers\")\n",
    "    wm_path = path.replace(\"originals\", \"weight_maps\")\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    for f in os.listdir(path):\n",
    "        # Limits dataset size for RAM compatibility\n",
    "        if count >= IMAGES_LIMIT:\n",
    "            break\n",
    "        \n",
    "        if not f.endswith(\".npy\"):\n",
    "            continue\n",
    "#         image = cv2.imread(os.path.join(path, f), cv2.IMREAD_GRAYSCALE)\n",
    "#         clahe = cv2.imread(os.path.join(clahe_path, f), cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "#         cell_mask = cv2.imread(os.path.join(mask_path, f), cv2.IMREAD_UNCHANGED)\n",
    "#         markers = cv2.imread(os.path.join(markers_path, f), cv2.IMREAD_UNCHANGED)\n",
    "#         weight_map = cv2.imread(os.path.join(wm_path, f), cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "        count += 1\n",
    "    \n",
    "#         image = np.load(os.path.join(path, f))\n",
    "        clahe = np.load(os.path.join(clahe_path, f))\n",
    "        cell_mask = np.load(os.path.join(mask_path, f))\n",
    "        markers = np.load(os.path.join(markers_path, f))\n",
    "        weight_map = np.load(os.path.join(wm_path, f))\n",
    "        print(\"   Loaded \" + os.path.join(mask_path, f) + \", \" + os.path.join(path, f.replace('mask', '')))\n",
    "\n",
    "        # Pack the data for the DataLoader\n",
    "        target = (cell_mask, markers, weight_map)\n",
    "        data.append((np.array([clahe]), target))\n",
    "    \n",
    "    train_size = int(0.8 * len(data))\n",
    "    test_size = len(data) - train_size\n",
    "    train_data, test_data = random_split(data, [train_size, test_size])\n",
    "    trainLoader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    testLoader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    return trainLoader, testLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2_SKo6FlhNt"
   },
   "outputs": [],
   "source": [
    "# Class for creating the CNN\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv11 = nn.Conv2d(768, 256, 3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(384, 128, 3, padding=1)\n",
    "        self.conv14 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv15 = nn.Conv2d(192, 64, 3, padding=1)\n",
    "        self.conv16 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv17 = nn.Conv2d(96, 32, 3, padding=1)\n",
    "        self.conv18 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv_out = nn.Conv2d(32, 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv1(x))\n",
    "        contraction_32 = F.relu(self.conv2(x))\n",
    "        \n",
    "        x = F.max_pool2d(contraction_32, kernel_size=2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        contraction_64 = F.relu(self.conv4(x))\n",
    "        \n",
    "        x = F.max_pool2d(contraction_64, kernel_size=2)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        contraction_128 = F.relu(self.conv6(x))\n",
    "        \n",
    "        x = F.max_pool2d(contraction_128, kernel_size=2)\n",
    "        x = F.relu(self.conv7(x))\n",
    "        contraction_256 = F.relu(self.conv8(x))\n",
    "        \n",
    "        x = F.max_pool2d(contraction_256, kernel_size=2)\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = F.relu(self.conv10(x))\n",
    "        \n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        x = torch.cat((contraction_256, x), dim=1)\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv12(x))\n",
    "        \n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        x = torch.cat((contraction_128, x), dim=1)\n",
    "        x = F.relu(self.conv13(x))\n",
    "        x = F.relu(self.conv14(x))\n",
    "        \n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        x = torch.cat((contraction_64, x), dim=1)\n",
    "        x = F.relu(self.conv15(x))\n",
    "        x = F.relu(self.conv16(x))\n",
    "        \n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        x = torch.cat((contraction_32, x), dim=1)\n",
    "        x = F.relu(self.conv17(x))\n",
    "        x = F.relu(self.conv18(x))\n",
    "        \n",
    "        x = self.conv_out(x)\n",
    "        output = F.sigmoid(x)\n",
    "        return output\n",
    "\n",
    "def weighted_mean_sq_error(inputs, targets_m, targets_c, weights):\n",
    "\n",
    "#     Weighted Mean Squared Error Loss takes in a weight map\n",
    "#     and computes loss based on both outputs\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('.', end='')\n",
    "    \n",
    "#     print(inputs.shape, targets_m.shape)\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    targets = [targets_m.to(device), targets_c.to(device)]\n",
    "    weights = weights.to(device)\n",
    "    loss = torch.zeros(inputs.shape[0])\n",
    "\n",
    "    # Calculate loss for each sample in the batch\n",
    "    for sample in range(inputs.shape[0]):\n",
    "#         print(\"Sample\", sample+1)\n",
    "        sample_loss, total_weight = 0.0, 0.0\n",
    "        \n",
    "        pred_markers = inputs[sample][0]\n",
    "        pred_cmask = inputs[sample][1]\n",
    "        \n",
    "#         pimg(pred_markers.cpu().detach().numpy())\n",
    "#         pimg(pred_cmasks.cpu().detach().numpy())\n",
    "#         pimg(weights.cpu().detach().numpy())\n",
    "        \n",
    "        exp_markers = targets[0][sample]\n",
    "        exp_cmask = targets[1][sample]\n",
    "        \n",
    "        numerator = weights[sample] * ( (pred_markers-exp_markers)**2 + (pred_cmask-exp_cmask)**2 )\n",
    "        \n",
    "        numerator = torch.sum(numerator)\n",
    "        \n",
    "        denominator = torch.sum(weights[sample])\n",
    "#         print(np.unique(exp_markers), np.unique(exp_cmasks), numerator, denominator)\n",
    "        sample_loss = 0.5 * (numerator/denominator)\n",
    "        \n",
    "        loss[sample] = sample_loss\n",
    "\n",
    "    return torch.mean(loss)\n",
    "\n",
    "\"\"\"\n",
    "def get_score(outputs, ground_truth):\n",
    "    \n",
    "    #Calculates Accuracy Score across the batch\n",
    "    \n",
    "    score = 0\n",
    "    batch_size = outputs.shape[0]\n",
    "    total = outputs.shape[1] * outputs.shape[2]\n",
    "    for sample in range(batch_size):\n",
    "        num_correct = torch.sum(outputs[sample] == ground_truth[sample]).item()\n",
    "        score += float(num_correct) / total\n",
    "\n",
    "    return score / batch_size\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Train 2 networks for predicting markers and the cell mask respectively\n",
    "    Set trains on data from \"Sequence 1 Masks\" and \"Sequence 2 Masks\"\n",
    "    and save the models\n",
    "    \"\"\"    \n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device: \" + str(device))\n",
    "    \n",
    "    # Net predicts the markers and cells\n",
    "    net = Network().to(device)\n",
    "    \n",
    "    # Calculate loss with Weighted MSE\n",
    "    criterion = weighted_mean_sq_error\n",
    "    \n",
    "    # Optimising using Adam algorithm\n",
    "    optimiser = optim.Adam(net.parameters(), lr=0.001)\n",
    "    \n",
    "    min_loss = 9999999999\n",
    "    file_count_c = 0\n",
    "    file_count_m = 0\n",
    "    \n",
    "    # Iterate over a number of epochs on the data\n",
    "    for epoch in range(100):\n",
    "        for i, batch in enumerate(trainLoader, 0):\n",
    "            x = batch[0].to(device)\n",
    "            target = batch[1]\n",
    "            cell_masks, markers = target[0].to(device), target[1].to(device) # Unpack target data\n",
    "            weight_map = target[2].to(device)\n",
    "\n",
    "            # Clear gradients from last step\n",
    "            optimiser.zero_grad()\n",
    "            \n",
    "            # Predict the markers from the image\n",
    "            output = net(x)\n",
    "            # loss_m = criterion(output_m, markers.long())\n",
    "            loss = criterion(output, markers.float(), cell_masks.float(), weight_map)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            if i == 0 or (i + 1) % 960 == 0:\n",
    "                print(f\"Epoch: {epoch+1}, Batch: {i + 1}\")\n",
    "                print(f\"Loss: {loss.item():.2f}\")\n",
    "                \n",
    "                plt.imshow(x[0][0].cpu(), cmap='gray')\n",
    "                plt.title(\"Input\")\n",
    "                plt.show()\n",
    "\n",
    "                # Get the predicted Cell Mask and Markers for one of the images\n",
    "                pred_m = ( (output[0][0] > 0.5).int() ).cpu()\n",
    "                pred_c = ( (output[0][1] > 0.5).int() ).cpu()\n",
    "                \n",
    "                # Compare predicted to true images\n",
    "                plot_two_images(pred_c.cpu(), cell_masks[0].cpu(), \"Predicted Cell Mask\", \"True Cell Mask\")\n",
    "                plot_two_images(pred_m.cpu(), markers[0].cpu(), \"Predicted Markers\", \"True Markers\")\n",
    "\n",
    "\n",
    "        # Test on the evaluation set\n",
    "        print(\"\\n--- Evaluation ---\")\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            running_loss = 0.0\n",
    "            for i, batch in enumerate(testLoader):\n",
    "                x = batch[0].to(device)\n",
    "                target = batch[1]\n",
    "                cell_masks, markers = target[0].to(device), target[1].to(device) # Unpack target data\n",
    "                weight_map = target[2].to(device)\n",
    "\n",
    "                output = net(x)\n",
    "                \n",
    "                pred_m = (output[:,0] > 0.5).int()\n",
    "                pred_c = (output[:,1] > 0.5).int()\n",
    "\n",
    "                running_loss += weighted_mean_sq_error(output, markers.float(), cell_masks.float(), weight_map)\n",
    "\n",
    "                if i == 0:\n",
    "                    plt.imshow(x[0][0].cpu(), cmap='gray')\n",
    "                    plt.title(\"Input\")\n",
    "                    plt.show()\n",
    "\n",
    "                    # Compare predicted to true images\n",
    "                    plot_two_images(pred_c[0].cpu(), cell_masks[0].cpu(), \"Predicted Cell Mask\", \"True Cell Mask\")\n",
    "                    plot_two_images(pred_m[0].cpu(), markers[0].cpu(), \"Predicted Markers\", \"True Markers\")\n",
    "\n",
    "            loss = running_loss / len(testLoader)\n",
    "            \n",
    "            if loss < min_loss:\n",
    "                torch.save(net.state_dict(), \"./CNN_min_loss_{}.pth\".format(file_count_c))\n",
    "                min_loss = loss\n",
    "                file_count_c += 1\n",
    "                file_count_c %= 20\n",
    "            \n",
    "            print(f\"EPOCH {epoch+1} LOSS: {loss:.3f}\\nMin Loss: {min_loss:.3f}\\n\\n\")\n",
    "        net.train()\n",
    "\n",
    "    torch.save(net.state_dict(), \"./CNN_v1.pth\")\n",
    "    print(\"Saved models. Min Loss : \", str(min_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j4icmg954Wpa"
   },
   "outputs": [],
   "source": [
    "print(\"Loading Data...\")\n",
    "trainLoader, testLoader = load_data('DIC-3_cache')\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S3L0jzi4lhN3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_networks_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('compvis': conda)",
   "language": "python",
   "name": "python38364bitcompvisconda46954d3d832c4b2f84bde7a1c3a50552"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
