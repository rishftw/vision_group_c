{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "train_networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5thgoDohupI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b2e9ec8-279a-4e2e-e3f6-729c9d808b50"
      },
      "source": [
        "%cd drive/My\\ Drive/Colab\\ Notebooks"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzxi4RNilhNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_networks: Training CNNs to be used by the main program\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import imutils\n",
        "import preprocessing\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from skimage.morphology import watershed, disk\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage.filters import meijering\n",
        "\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "\n",
        "def plot_two_images(imgL, imgR, titleL, titleR):\n",
        "    f = plt.figure()\n",
        "    f.add_subplot(1,2, 1)\n",
        "    plt.imshow(imgL, cmap='gray')\n",
        "    plt.title(titleL)\n",
        "    f.add_subplot(1,2, 2)\n",
        "    plt.imshow(imgR, cmap='gray')\n",
        "    plt.title(titleR)\n",
        "    plt.show(block=True)\n",
        "    \n",
        "def load_data(dataset):\n",
        "    \"\"\"\n",
        "    Returns a list of dictionaries containing an image and the corresponding mask\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    paths = [dataset + '/Sequence 1', dataset + '/Sequence 2']\n",
        "    for path in paths:\n",
        "        mask_path = path + ' Masks'\n",
        "        for f in os.listdir(mask_path):\n",
        "            if not f.endswith(\".tif\"):\n",
        "                continue\n",
        "            image = cv2.imread(os.path.join(path, f.replace('mask', '')), cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "            mask = cv2.imread(os.path.join(mask_path, f), cv2.IMREAD_UNCHANGED)\n",
        "            print(\"   Loaded \" + os.path.join(mask_path, f) + \", \" + os.path.join(path, f.replace('mask', '')))\n",
        "            \n",
        "            # Generate the Cell Mask and Markers from the Mask\n",
        "            cell_mask = (mask > 0).astype(np.float32)\n",
        "            markers = (preprocessing.get_cell_markers(mask) > 0).astype(np.float32)\n",
        "            weight_map = preprocessing.get_weight_map(markers)\n",
        "            \n",
        "            # Pack the data for the DataLoader\n",
        "            target = (np.array([cell_mask]), np.array([markers]), weight_map)\n",
        "            data.append((np.array([image]), target))\n",
        "            \n",
        "    return DataLoader(data, batch_size=9, shuffle=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2_SKo6FlhNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class for creating the CNN\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.conv7 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv8 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.conv9 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.conv10 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv11 = nn.Conv2d(768, 256, 3, padding=1)\n",
        "        self.conv12 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.conv13 = nn.Conv2d(384, 128, 3, padding=1)\n",
        "        self.conv14 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.conv15 = nn.Conv2d(192, 64, 3, padding=1)\n",
        "        self.conv16 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.conv17 = nn.Conv2d(96, 32, 3, padding=1)\n",
        "        self.conv18 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.conv_out = nn.Conv2d(32, 2, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the network\n",
        "        \"\"\"\n",
        "        x = F.relu(self.conv1(x))\n",
        "        contraction_32 = F.relu(self.conv2(x))\n",
        "        \n",
        "        x = F.max_pool2d(contraction_32, kernel_size=2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        contraction_64 = F.relu(self.conv4(x))\n",
        "        \n",
        "        x = F.max_pool2d(contraction_64, kernel_size=2)\n",
        "        x = F.relu(self.conv5(x))\n",
        "        contraction_128 = F.relu(self.conv6(x))\n",
        "        \n",
        "        x = F.max_pool2d(contraction_128, kernel_size=2)\n",
        "        x = F.relu(self.conv7(x))\n",
        "        contraction_256 = F.relu(self.conv8(x))\n",
        "        \n",
        "        x = F.max_pool2d(contraction_256, kernel_size=2)\n",
        "        x = F.relu(self.conv9(x))\n",
        "        x = F.relu(self.conv10(x))\n",
        "        \n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
        "        x = torch.cat((contraction_256, x), dim=1)\n",
        "        x = F.relu(self.conv11(x))\n",
        "        x = F.relu(self.conv12(x))\n",
        "        \n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
        "        x = torch.cat((contraction_128, x), dim=1)\n",
        "        x = F.relu(self.conv13(x))\n",
        "        x = F.relu(self.conv14(x))\n",
        "        \n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
        "        x = torch.cat((contraction_64, x), dim=1)\n",
        "        x = F.relu(self.conv15(x))\n",
        "        x = F.relu(self.conv16(x))\n",
        "        \n",
        "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
        "        x = torch.cat((contraction_32, x), dim=1)\n",
        "        x = F.relu(self.conv17(x))\n",
        "        x = F.relu(self.conv18(x))\n",
        "        \n",
        "        x = self.conv_out(x)\n",
        "        output = F.softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "def weighted_cross_entropy_loss(inputs, targets, weights):\n",
        "    \"\"\"\n",
        "    Weighted Cross-Entropy Loss takes in a weight map\n",
        "    and computes loss\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cpu\")\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "    weights = weights.to(device)\n",
        "    loss = torch.zeros(inputs.shape[0], requires_grad=True)\n",
        "    # Calculate loss for each sample\n",
        "    for sample in range(inputs.shape[0]):\n",
        "        print(sample+1)\n",
        "        sample_loss, total_weight = 0.0, 0.0\n",
        "        for row in range(inputs.shape[2]):\n",
        "            for col in range(inputs.shape[3]):\n",
        "                # Get pixel q\n",
        "                q = (row, col)\n",
        "                w = weights[sample][q]\n",
        "                total_weight += w\n",
        "                if targets[sample][0][q] == 0:\n",
        "                    # Get predicted probability for q == 0\n",
        "                    p = inputs[sample][0][q].detach().cpu().numpy()\n",
        "                else:\n",
        "                    # Get predicted probability for q == 1\n",
        "                    p = inputs[sample][1][q].detach().cpu().numpy()\n",
        "                sample_loss -= w * np.log(p)\n",
        "        sample_loss = sample_loss / total_weight\n",
        "        loss[sample] = sample_loss\n",
        "\n",
        "    return torch.mean(loss)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Train 2 networks for predicting markers and the cell mask respectively\n",
        "    Set trains on data from \"Sequence 1 Masks\" and \"Sequence 2 Masks\"\n",
        "    and save the models\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device: \" + str(device))\n",
        "    \n",
        "    # Net M predicts the markers. Net C predicts the cell mask\n",
        "    net_m, net_c = Network().to(device), Network().to(device)\n",
        "    \n",
        "    criterion = weighted_cross_entropy_loss\n",
        "    \n",
        "    # Optimising using Adam algorithm\n",
        "    optimiser_m = optim.Adam(net_m.parameters(), lr=0.001)\n",
        "    optimiser_c = optim.Adam(net_c.parameters(), lr=0.001)\n",
        "    \n",
        "    # Iterate over a number of epochs on the data\n",
        "    for epoch in range(10):\n",
        "        for i, batch in enumerate(trainLoader):\n",
        "            x = batch[0].to(device)\n",
        "            target = batch[1]\n",
        "            cell_masks, markers = target[0].to(device), target[1].to(device) # Unpack target data\n",
        "            weight_map = target[2].to(device)\n",
        "\n",
        "            # Clear gradients from last step\n",
        "            optimiser_m.zero_grad()\n",
        "            optimiser_c.zero_grad()\n",
        "\n",
        "            # Predict the markers from the image\n",
        "            output_m = net_m(x)\n",
        "            loss_m = criterion(output_m, markers, weight_map)\n",
        "            print(loss_m)\n",
        "            loss_m.backward()\n",
        "            optimiser_m.step()\n",
        "            \n",
        "            # Predict the Cell Mask from the image\n",
        "            output_c = net_c(x)\n",
        "            loss_c = criterion(output_c, cell_masks, weight_map)\n",
        "            loss_c.backward()\n",
        "            optimiser_c.step()\n",
        "\n",
        "            if epoch >= 0:\n",
        "                print(f\"Epoch: {epoch+1}, Batch: {i + 1}\")\n",
        "                \n",
        "                plt.imshow(x[0][0].cpu(), cmap='gray')\n",
        "                plt.title(\"Input\")\n",
        "                plt.show()\n",
        "                plt.imshow(weight_map[0].cpu(), cmap='gray')\n",
        "                plt.title(\"Weight Map\")\n",
        "                plt.show()\n",
        "\n",
        "                # Get the predicted Cell Mask and Markers for one of the images\n",
        "                pred_c = (output_c[0][0] > 0.5).type(torch.FloatTensor)\n",
        "                pred_m = (output_m[0][0] > 0.5).type(torch.FloatTensor)\n",
        "                \n",
        "                # Compare predicted to true images\n",
        "                plot_two_images(pred_c, cell_masks[0][0].cpu(), \"Predicted Cell Mask\", \"True Cell Mask\")\n",
        "                plot_two_images(pred_m, markers[0][0].cpu(), \"Predicted Markers\", \"True Markers\")\n",
        "\n",
        "    torch.save(net_m.state_dict(), \"./CNN_m.pth\")\n",
        "    torch.save(net_c.state_dict(), \"./CNN_c.pth\")\n",
        "    print(\"Saved models.\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4icmg954Wpa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "16926e88-d4bd-4c4b-87db-9e59e279e0eb"
      },
      "source": [
        "print(\"Loading Data...\")\n",
        "trainLoader = load_data('DIC-C2DH-HeLa')\n",
        "print(\"Finished.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Data...\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 1 Masks/t002mask.tif, DIC-C2DH-HeLa/Sequence 1/t002.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 1 Masks/t031mask.tif, DIC-C2DH-HeLa/Sequence 1/t031.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 1 Masks/t005mask.tif, DIC-C2DH-HeLa/Sequence 1/t005.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 1 Masks/t021mask.tif, DIC-C2DH-HeLa/Sequence 1/t021.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 1 Masks/t034mask.tif, DIC-C2DH-HeLa/Sequence 1/t034.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 1 Masks/t067mask.tif, DIC-C2DH-HeLa/Sequence 1/t067.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 1 Masks/t054mask.tif, DIC-C2DH-HeLa/Sequence 1/t054.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 1 Masks/t039mask.tif, DIC-C2DH-HeLa/Sequence 1/t039.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 1 Masks/t033mask.tif, DIC-C2DH-HeLa/Sequence 1/t033.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 2 Masks/t061mask.tif, DIC-C2DH-HeLa/Sequence 2/t061.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 2 Masks/t027mask.tif, DIC-C2DH-HeLa/Sequence 2/t027.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 2 Masks/t006mask.tif, DIC-C2DH-HeLa/Sequence 2/t006.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 2 Masks/t038mask.tif, DIC-C2DH-HeLa/Sequence 2/t038.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 2 Masks/t042mask.tif, DIC-C2DH-HeLa/Sequence 2/t042.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 2 Masks/t034mask.tif, DIC-C2DH-HeLa/Sequence 2/t034.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 2 Masks/t014mask.tif, DIC-C2DH-HeLa/Sequence 2/t014.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 2 Masks/t007mask.tif, DIC-C2DH-HeLa/Sequence 2/t007.tif\n",
            "   Loaded DIC-C2DH-HeLa/Sequence 2 Masks/t067mask.tif, DIC-C2DH-HeLa/Sequence 2/t067.tif\n",
            "Finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3L0jzi4lhN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "242e62ee-fe12-4214-f41e-bc6e5454427a"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "tensor(1.7264, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-ee31a450e471>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mloss_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mloss_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0moptimiser_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: leaf variable has been moved into the graph interior"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikuoC1VI90Le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.randn(2, 2, 3, 3)\n",
        "loss = torch.zeros(a.shape[0])\n",
        "print(a)\n",
        "b, _ = torch.max(a, dim=1)\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gZyJE2mnnU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.randn(3, 3).cuda()\n",
        "print(a[1][1].detach().cpu().numpy())\n",
        "print(a[1][1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}